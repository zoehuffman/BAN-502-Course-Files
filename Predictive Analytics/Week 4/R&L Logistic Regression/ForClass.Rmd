### NCAA Tournament Prediction

Objective: Estimate probability a team wins if matched-up with any other team in the 2022 Men's NCAA Basketball tournament. Work was done as part of a Kaggle competition. The competition is described here: https://www.kaggle.com/competitions/mens-march-mania-2022/data. I finished in 134th place out of 930 submissions. :)

#### Libraries

Load the necessary libraries.  
```{r, include = FALSE}
library(tidyverse)  
library(tidymodels)
library(usemodels)
library(glmnet)
library(ROCR)
```

#### Read-In Data
```{r}
results = read_csv("cleaned.csv")
results = results %>% select(-...1) #getting rid of residual row number column
```

```{r}
str(results)
summary(results)
```
Convert response to a factor
```{r}
results = results %>% mutate(Team_A_Win = as_factor(Team_A_Win))
str(results)
```

#### Lasso Regression

Set-up folds (can be used for other model types also). I'm doing my k-fold splits here a little bit differently than is traditional. Sometimes it can make sense to set up the folds to follow a logical structure that exists in the data. Here the data is structured by season, so I'll use that structure for my folds.  
```{r}
set.seed(5144)
folds = group_vfold_cv(results, group = "Season")
```

Used "usemodels" package here to create code template for lasso and ridge
```{r}
#use_glmnet(Team_A_Win ~ Massey_A + Massey_B + Pomeroy_A + Pomeroy_B + 
#             TORV_A + TORV_B + ADJOE_A + ADJOE_B + ADJDE_A + ADJDE_B, data = results)
```

Here's the recipe. Mixture is set to 1 for Lasso. We'll try 100 lambda values. I'm using a different metric instead of accuracy. The Kaggle competition scored submissions by a metric called log loss. So I'll use min log loss as my metric.  
```{r}
glmnet_recipe <- 
  recipe(formula = Team_A_Win ~ TORV_A + TORV_B + Seed_Diff + ADJOE_A + 
           ADJOE_B + ADJDE_A + ADJDE_B + `EFG%_A` + `EFG%_B` + ORB_A + 
           ORB_B + TOR_A + TOR_B + FTR_A + FTR_B, data = results) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_normalize(all_predictors(), -all_nominal()) 

glmnet_spec <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_mode("classification") %>% 
  set_engine("glmnet") 

glmnet_workflow <- 
  workflow() %>% 
  add_recipe(glmnet_recipe) %>% 
  add_model(glmnet_spec) 

glmnet_grid = grid_regular(penalty(), levels = 100)

#note the use of alternative metric (min log loss)
glmnet_tune <- 
  tune_grid(glmnet_workflow, resamples = folds, 
            grid = glmnet_grid, metrics = metric_set(mn_log_loss))
```

```{r}
glmnet_tune %>%
  collect_metrics() %>%
  ggplot(aes(penalty, mean)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  theme(legend.position = "none")
```

Let's zoom in a bit.
```{r}
glmnet_tune %>%
  collect_metrics() %>%
  ggplot(aes(penalty, mean)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  theme(legend.position = "none") + 
  xlim(0,0.1)
```


What is the exact best value?  
```{r}
best_mnlog = glmnet_tune %>%
  select_best("mn_log_loss")
best_mnlog
```
Finalize the workflow
```{r}
final_lasso = glmnet_workflow %>% finalize_workflow(best_mnlog)
```

Fit the finalized workflow to the data
```{r}
lasso_fit = fit(final_lasso, results)
```

Take a look at the model coefficients
```{r}
options(scipen = 999)
lasso_fit %>%
  extract_fit_parsnip() %>%
  pluck("fit")  %>% 
  coef(s = best_mnlog$penalty) #show the coefficients for our selected lambda value
options(scipen = 0)
```

A Tidy view
```{r}
tidy(lasso_fit)
```

Developing predictions and thinking about thresholds.  
```{r}
predictions = predict(lasso_fit, results, type="prob")[2]

ROCRpred = prediction(predictions, results$Team_A_Win) 

###You shouldn't need to ever change the next two lines:
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
```

```{r}
#Determine threshold to balance sensitivity and specificity
#DO NOT modify this code
opt.cut = function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(ROCRperf, ROCRpred))
```
